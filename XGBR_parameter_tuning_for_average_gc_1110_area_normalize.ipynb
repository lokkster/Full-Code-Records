{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3algFTwbg6Th"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/average GC full dataset new 1110 for colab.csv')\n",
        "!pip install xgboost==1.6.1\n",
        "import pickle\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/average GC full dataset new 1110 for colab area amplified arranged for colab.csv')"
      ],
      "metadata": {
        "id": "wJ6y7fbQgXnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=data.iloc[:,:5].values\n",
        "Y = data.iloc[:,5:].values\n",
        "\n",
        "train_data,test_data,train_targets,test_targets=train_test_split(X,Y,test_size=0.11,random_state=42)\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(test_data[0])"
      ],
      "metadata": {
        "id": "UC2jzTp2hFFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "def mae(actual,pred):\n",
        "     return (mean_absolute_error(actual,pred))\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "def mape(actual,pred):\n",
        "    calc=np.mean(np.absolute((actual-pred)*100/actual))\n",
        "    return calc"
      ],
      "metadata": {
        "id": "ctI3PxR2hIKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "xgbr=XGBRegressor()"
      ],
      "metadata": {
        "id": "wHvwGoXIkwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "taking default params"
      ],
      "metadata": {
        "id": "ZsQMgRHCsdAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "defparam=xgbr.get_params()\n",
        "print(defparam)"
      ],
      "metadata": {
        "id": "ou9HVDX3scpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr.fit(train_data,train_targets)\n",
        "predxgb=xgbr.predict(test_data)\n",
        "print(predxgb)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predxgb))\n",
        "print(\"mape:\",mape(test_targets,predxgb))\n",
        "xgbr.save_model('/content/drive/MyDrive/Colab Notebooks/xgbr_avggc5inareanorm.h5')"
      ],
      "metadata": {
        "id": "06mSnVztnNrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predxgb,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predxgb))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "kVKQoDPE5gwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "individual parameter settings: mixed, but min child weight is altered"
      ],
      "metadata": {
        "id": "FpHnVpV-FvQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgbrne=XGBRegressor(n_estimators=1000,min_child_weight=1,max_depth=7,subsample=0.9,colsample_bytree=.9,learning_rate=0.1)\n",
        "xgbrne.fit(train_data,train_targets)\n",
        "predxgbne=xgbrne.predict(test_data)\n",
        "print(predxgbne)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predxgbne))\n",
        "print(\"mape:\",mape(test_targets,predxgbne))\n",
        "xgbrne.save_model('/content/drive/MyDrive/Colab Notebooks/xgbr_avggc5in1110areanorm.h5')"
      ],
      "metadata": {
        "id": "QLbcX0hlFu7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgbrne.feature_importances_)"
      ],
      "metadata": {
        "id": "0F4TSkn-Yznh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predxgbne,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predxgbne))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "KN-lhpLFDHam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c2 only r2"
      ],
      "metadata": {
        "id": "sg9U7mkbOu5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predc2=predxgbne[:,3]\n",
        "testtargetsc2=test_targets[:,3]\n",
        "print(predc2)\n",
        "print(testtargetsc2)\n",
        "\n",
        "r2c2=r2_score(testtargetsc2,predc2)\n",
        "print(r2c2)"
      ],
      "metadata": {
        "id": "Ffveq9G3OcXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature importance"
      ],
      "metadata": {
        "id": "l2tOkjh4EFRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get importance\n",
        "importance = xgbrne.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        " print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "EGhYgPKbEFHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_n77KHGEFAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross validation"
      ],
      "metadata": {
        "id": "tOdhFYZaRBRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "cvsxgbr=cross_val_score(xgbrne,train_data,train_targets,cv=cv,n_jobs=-1,scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "print(cvsxgbr)\n"
      ],
      "metadata": {
        "id": "1Hqa1BbaQ_1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "scores=mean(absolute(cvsxgbr))\n",
        "\n",
        "print(scores)\n"
      ],
      "metadata": {
        "id": "lklef1DQWooc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "new_model=XGBRegressor()\n",
        "new_model.load_model('/content/drive/MyDrive/Colab Notebooks/xgbr_avggc5inareanorm.h5')\n",
        "\n",
        "predxgbne2=new_model.predict(test_data)\n",
        "print(predxgbne2)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predxgbne2))\n",
        "print(\"mape:\",mape(test_targets,predxgbne2))\n",
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predxgbne2,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predxgbne2))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "PznrIngvDHIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(predxgbne[0])\n",
        "sum=numpy.sum(predxgbne[0])\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "J7a_6NnJz6xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import LeavePOut\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "LTgnOW4MmZNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = xgbrne.score(test_data, test_targets)\n",
        "print(\"Accuracy: %.2f%%\" % (result*100.0))"
      ],
      "metadata": {
        "id": "6yPUvpK8mbvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kfold cv\n"
      ],
      "metadata": {
        "id": "uPQmRE7jnOqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = model_selection.KFold(n_splits=10)\n",
        "model_kfold = xgbrne\n",
        "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
      ],
      "metadata": {
        "id": "AV8sNVqanOEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "repeated kfold\n"
      ],
      "metadata": {
        "id": "kaW2JUaroZsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "cv=RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(xgbrne, X, Y, scoring='r2', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "0sY3BCr0oej9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random search on individual variables\n"
      ],
      "metadata": {
        "id": "2Tz1NlGI2rdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 200000, num = 50)]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators}\n",
        "xgbr_random = GridSearchCV(estimator = xgbr, param_grid= random_grid,  cv = 2, verbose=2, n_jobs = -1)\n",
        "#xgbr_random = GridSearchCV(estimator = xgbr, param_distributions = random_grid, n_iter =100, cv = 3, verbose=0, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "xgbr_random.fit(train_data, train_targets)"
      ],
      "metadata": {
        "id": "TaubmlNe2uRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "randomsearchcv\n"
      ],
      "metadata": {
        "id": "4-iLUxbUMz-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 20000, num = 20)]\n",
        "# min child weight\n",
        "min_child_weight = [2,4,6,8,10]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# learning rate\n",
        "learning_rate = [0.01,0.1,0.5,1]\n",
        "# solsample by tree\n",
        "colsample_bytree = [0.5,0.7,0.9]\n",
        "#subsample\n",
        "subsample=[0.5,0.7,0.9]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'max_depth': max_depth,\n",
        "               'min_child_weight': min_child_weight,\n",
        "               'learning_rate': learning_rate,\n",
        "               'colsample_bytree': colsample_bytree,\n",
        "               'n_estimators': n_estimators,\n",
        "               'subsample': subsample,\n",
        "              }\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "tu-6KtV0M1iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "xgbr_random = RandomizedSearchCV(estimator = xgbr, param_distributions = random_grid, n_iter =800, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "xgbr_random.fit(train_data, train_targets)"
      ],
      "metadata": {
        "id": "Ref09pDcOmMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgbr_random.best_params_)"
      ],
      "metadata": {
        "id": "JlxFQNiBV-nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bayesian optimization method on certain features\n"
      ],
      "metadata": {
        "id": "bKkdqereMVT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "id": "jBeEBZXEIFW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Xtra Gradient Boosting Machine\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "def xgbm_cl_bo(max_depth,min_child_weight, learning_rate, colsample_bytree,n_estimators, subsample):\n",
        "    params_gbm = {}\n",
        "    params_gbm['max_depth'] = round(max_depth)\n",
        "    params_gbm['min_child_weight'] = min_child_weight\n",
        "    params_gbm['learning_rate'] = learning_rate\n",
        "    params_gbm['colsample_bytree'] = colsample_bytree\n",
        "    params_gbm['n_estimators'] = round(n_estimators)\n",
        "    params_gbm['subsample'] = subsample\n",
        "    scores = cross_val_score(XGBRegressor(random_state=0, **params_gbm),\n",
        "                             train_data,train_targets, cv=5).mean()\n",
        "    score = scores.mean()\n",
        "    return score"
      ],
      "metadata": {
        "id": "kHrQRpVyQDQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Bayesian Optimization\n",
        "import time\n",
        "start = time.time()\n",
        "params_gbm ={\n",
        "    'max_depth':(3, 10),\n",
        "    'min_child_weight':(1,10),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'colsample_bytree':(0.5,0.9),\n",
        "    'n_estimators':(80,5000),\n",
        "    'subsample': (0.5, 0.9)\n",
        "            }\n",
        "gbm_bo = BayesianOptimization(xgbm_cl_bo, params_gbm, random_state=0)\n",
        "gbm_bo.maximize(init_points=1000, n_iter=6)\n",
        "print('It takes %s minutes' % ((time.time() - start)/60))"
      ],
      "metadata": {
        "id": "VfSPalkiRVcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_gbm = gbm_bo.max['params']\n",
        "params_gbm['max_depth'] = round(params_gbm['max_depth'])\n",
        "params_gbm['n_estimators'] = round(params_gbm['n_estimators'])\n",
        "params_gbm"
      ],
      "metadata": {
        "id": "Xdl744bdVuCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.9,\n",
        " 'learning_rate': 0.033727271369527585,\n",
        " 'max_depth': 7,\n",
        " 'min_child_weight': 1.8518249906475186,\n",
        " 'n_estimators': 93,\n",
        " 'subsample': 0.9}\n",
        " 10/28\n",
        " mae: 2.8657398451131537\n",
        "mape: 20.80642400363375"
      ],
      "metadata": {
        "id": "agudOLKKloN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgbrnew=XGBRegressor(n_estimators=93,max_depth=7,min_child_weight=1.852,subsample=0.9,learning_rate=0.033727,colsample_bytree=0.9)\n",
        "xgbrnew.fit(train_data,train_targets)\n",
        "predxgb2=xgbrnew.predict(test_data)\n",
        "print(predxgb2)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predxgb2))\n",
        "print(\"mape:\",mape(test_targets,predxgb2))"
      ],
      "metadata": {
        "id": "GhFd3_UEm1a6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}