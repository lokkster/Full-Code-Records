{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3algFTwbg6Th"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/average GC full dataset new 1110 for colab.csv')\n",
        "!pip install xgboost==1.6.1\n",
        "import pickle\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/average GC full dataset new 1110 for colab area amplified arranged for colab.csv')\n"
      ],
      "metadata": {
        "id": "0RCugDQ1_iXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=data.iloc[:,:5].values\n",
        "Y = data.iloc[:,5:].values\n",
        "\n",
        "train_data,test_data,train_targets,test_targets=train_test_split(X,Y,test_size=0.11,random_state=42)\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(test_data[0])"
      ],
      "metadata": {
        "id": "UC2jzTp2hFFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "def mae(actual,pred):\n",
        "     return (mean_absolute_error(actual,pred))\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "def mape(actual,pred):\n",
        "    calc=np.mean(np.absolute((actual-pred)*100/actual))\n",
        "    return calc"
      ],
      "metadata": {
        "id": "ctI3PxR2hIKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "gbrm=MultiOutputRegressor(GradientBoostingRegressor())"
      ],
      "metadata": {
        "id": "wHvwGoXIkwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "taking default params"
      ],
      "metadata": {
        "id": "ZsQMgRHCsdAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "defparam=gbrm.get_params()\n",
        "print(defparam)"
      ],
      "metadata": {
        "id": "ou9HVDX3scpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbrm.fit(train_data,train_targets)\n",
        "predgb=gbrm.predict(test_data)\n",
        "\n",
        "print(predgb)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predgb))\n",
        "print(\"mape:\",mape(test_targets,predgb))\n"
      ],
      "metadata": {
        "id": "06mSnVztnNrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predgb,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predgb))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "d6wJuqFSoo6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "individual parameter settings: mixed, but max_depth is altered"
      ],
      "metadata": {
        "id": "ytCC7yA6Pmem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbrmnew=MultiOutputRegressor(GradientBoostingRegressor(max_features=1,max_depth=4,min_samples_leaf=1,min_samples_split=2,n_estimators=1000,learning_rate=0.3))  \n",
        "gbrmnew.fit(train_data,train_targets)\n",
        "predgbnew=gbrmnew.predict(test_data)\n",
        "\n",
        "print(predgbnew)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predgbnew))\n",
        "print(\"mape:\",mape(test_targets,predgbnew))"
      ],
      "metadata": {
        "id": "6VlgeZ_UPwJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predgbnew,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predgbnew))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "zQhM79oyofZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an iterator object with write permission - model.pkl\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/gbr_avggc1110areanorm.pkl\", 'wb') as files:\n",
        "    pickle.dump(gbrmnew, files)"
      ],
      "metadata": {
        "id": "dy9i2ptF5JHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predgbnew,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predgbnew))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "k9xcXwlntce9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gbr\n",
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/gbr_avggc1110areanorm.pkl\" , 'rb') as f:\n",
        "    new_model = pickle.load(f)\n",
        "\n",
        "predgbnew2=new_model.predict(test_data)\n",
        "\n",
        "print(predgbnew2)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predgbnew2))\n",
        "print(\"mape:\",mape(test_targets,predgbnew2))\n",
        "from sklearn.metrics import r2_score\n",
        "r2=r2_score(test_targets,predgbnew2,multioutput=\"variance_weighted\")\n",
        "print(r2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "rmse=sqrt(mean_squared_error(test_targets,predgbnew2))\n",
        "print(\"rmse:\",rmse)"
      ],
      "metadata": {
        "id": "WjmxMs_4IiSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "cvsxgbr=cross_val_score(gbrmnew,train_data,train_targets,cv=cv,n_jobs=-1,scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "print(cvsxgbr)"
      ],
      "metadata": {
        "id": "ZMg-Tw1ofnxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean,absolute\n",
        "scores=mean(absolute(cvsxgbr))\n",
        "\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "vK0UNgwZfz3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomsearch cv\n"
      ],
      "metadata": {
        "id": "bKkdqereMVT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 20000, num = 20)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5,8, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2,3, 4]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'estimator__n_estimators': n_estimators,\n",
        "               'estimator__max_features': max_features,\n",
        "               'estimator__max_depth': max_depth,\n",
        "               'estimator__min_samples_split': min_samples_split,\n",
        "               'estimator__min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "wXBU3W-EVYfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "gbr_random = RandomizedSearchCV(estimator = gbrm, param_distributions = random_grid, n_iter =1000, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "gbr_random.fit(train_data, train_targets)"
      ],
      "metadata": {
        "id": "bCuDq_42wnKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gbr_random.best_params_)"
      ],
      "metadata": {
        "id": "ipB12WUQwqgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'estimator__n_estimators': 7494, 'estimator__min_samples_split': 8, 'estimator__min_samples_leaf': 1, 'estimator__max_features': 'sqrt', 'estimator__max_depth': 10} 10/28\n",
        "\n",
        "mae: 2.360238787763666\n",
        "mape: 16.33349565631594"
      ],
      "metadata": {
        "id": "_r0pQRkWlaWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbrnew=MultiOutputRegressor(GradientBoostingRegressor(n_estimators=7494,min_samples_split=8,min_samples_leaf=1,max_features='sqrt',max_depth=10))\n",
        "gbrnew.fit(train_data,train_targets)\n",
        "predgbnew=gbrnew.predict(test_data)\n",
        "\n",
        "print(predgbnew)\n",
        "print(test_targets)\n",
        "print(\"mae:\",mae(test_targets,predgbnew))\n",
        "print(\"mape:\",mape(test_targets,predgbnew))"
      ],
      "metadata": {
        "id": "lE7zcV78fB1b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}